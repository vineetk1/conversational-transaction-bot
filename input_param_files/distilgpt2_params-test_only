Vineet Kumar, sioom.ai

This input file has a unique set of user-settable hyper-parameters for
testing a checkpointed model. It is envisioned that there will be many input
files, in the "input_param_files" directory, each with their own unique set
of hyperparameters.

Note the following:
	(1) This file should be last in the command-line.
	(2) Do NOT change the order of python-dictionaries in this file.
	(3) The default directory is "conversational-transaction-bot"
 
Command-line:
-------------
python3 ctbLoadTest.py input_param_files/distilgpt2_params-test_only 

Path to ctb logs files:
-----------------------
It is the default directory, and the name of the file is "ctb_logs".

Path to TensorBoard logs files:
-----------------------------
It includes the following directory: tensorboard_logs. Following is an example:
tensorboard_logs/distilgpt2_params/version_0

Path to Checkpointed files:
---------------------------
It includes the following directories: (i) path of TensorBoard logs files,
(ii) checkpoints. Following is an example:
tensorboard_logs//distilgpt2_params/version_0/checkpoints

Name of Checkpointed files:
---------------------------
During training, the last epoch is always checkpointed in the file 'last.ckpt'. 
Additionally, epochs with the lowest validation loss are also checkpointed. The
names of these files includes the epoch number plus the value of the
validation loss. Following is an example:
last.ckpt, 'epoch=10-val_loss=0.23297.ckpt', 'epoch=22-val_loss=0.14760.ckpt'


parameters for file "ctbMain.py"
- 'chkpt': 'path to checkpoint file that will be loaded'
- 'pass_fail_stat': whether to gather statistics	Default: False
- 
{'chkpt': 'ctb_lightning_logs/distilgpt2_params/version_0/checkpoints/epoch=02-val_loss=0.1540.ckpt', 'pass_fail_stat': False}


parameters for file "ctbModel.py"
- Dictionary MUST be empty because these parameters are loaded from checkpoint file
- 
{}


parameters for file "ctbData.py"
- 'default_format_path': 'path to training dataset'
- 
{'default_format_path': 'data/dialog-bAbI-tasks/dstc2/defaultFormat.train'} 


parameters for Lightning Trainer
- For a list of parameters, see Trainer.__init__(...) in PyTorch Lightning documentation
- 
{'gpus': 1, 'auto_scale_batch_size': True}

