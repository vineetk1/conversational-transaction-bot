Vineet Kumar, sioom.ai

This input file has user-settable hyper-parameters for loading a checkpoint model
   and training it with different hyperparameters
Use Case: A user stops training in order to re-train with different
    hyper-parameters. Training can be stopped through the keystroke ctrl-c or by 
    using appropriate  hyperparameters.

Note the following:
	(1) This file name should be last in the command-line.
	(2) Do NOT change the order of python-dictionaries in this file.
	(3) The default directory is "conversational-transaction-bot"
 
Command-line:
-------------
python3 ctbMain.py input_param_files/distilgpt2_dstc2-load_change_params 


parameters for python-dictionary #0
-
{'save_top_k': 2, 'no_testing': True, 'chkpt': 'tensorboard_logs/model_type=distilgpt2-dstc2,tokenizer_type=gpt2-dstc2/version_21/checkpoints/last.ckpt'}


parameters for python-dictionary #1
- 
#{'model_type': 'distilgpt2-dstc2', 'tokenizer_type': 'gpt2-dstc2', 'optz': 'Adam', 'optz_params': {'lr': 8.31528719e-7}} 
{'model_type': 'distilgpt2-dstc2', 'tokenizer_type': 'gpt2-dstc2', 'optz': 'Adam', 'optz_params': {'lr': 1e-06}, 'lr_sched': 'ReduceLROnPlateau', 'lr_sched_params': {'mode': 'min', 'patience': 3, 'factor': 0.001}} 
#{'model_type': 'distilgpt2-dstc2', 'tokenizer_type': 'gpt2-dstc2', 'optz': 'SGD', 'optz_params': {'lr': 1.831563888e-2, 'momentum': 0.9, 'nesterov': True}, 'lr_sched': 'ReduceLROnPlateau', 'lr_sched_params': {'mode': 'min', 'patience': 9}}
# If lr_sched=CyclicLR, then base_lr is the initial learning-rate
#{'optz': 'SGD', 'optz_params': {'lr': 0, 'momentum': 0.9, 'nesterov': True}, 'lr_sched': 'CyclicLR', 'lr_sched_params': {'base_lr': 1e-6, 'max_lr': 1e-4}} 


parameters for python-dictionary #2
- 
{'default_format_path': 'data/dialog-bAbI-tasks/dstc2/defaultFormat.train', 'batch_size': 2} 


parameters for python-dictionary #3
- 
{'gpus': 1}

